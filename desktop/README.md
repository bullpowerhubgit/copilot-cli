# ğŸ–¥ï¸ Copilot Desktop Client

Eine **kostenlose Desktop-Anwendung** mit grafischer BenutzeroberflÃ¤che fÃ¼r AI-Assistenz!

![Desktop App](https://img.shields.io/badge/Platform-Windows%20%7C%20macOS%20%7C%20Linux-blue)
![License](https://img.shields.io/badge/License-MIT-green)

## âœ¨ Features

- ğŸ¨ **Moderne grafische OberflÃ¤che** - Dark Mode Design
- ğŸ’¬ **Echtzeit-Chat** - FlÃ¼ssiges Konversationserlebnis
- ğŸš€ **17 kostenlose AI-Modelle** - Groq, Google Gemini, Ollama, etc.
- ğŸ’¾ **Chat-Export** - Speichere deine Konversationen
- âš™ï¸ **Einfache Konfiguration** - API-Keys direkt in der App verwalten
- ğŸ“Š **Statistiken** - Behalte den Ãœberblick Ã¼ber deine Chats
- ğŸ”’ **Sicher** - Alle Daten bleiben lokal auf deinem PC

## ğŸ“¦ Installation

### Option 1: Von Source ausfÃ¼hren (Entwicklung)

```powershell
# 1. In den Desktop-Ordner wechseln
cd desktop

# 2. Dependencies installieren
npm install

# 3. App starten
npm start
```

### Option 2: Installierbare App bauen

```powershell
# FÃ¼r Windows
npm run build:win

# FÃ¼r macOS
npm run build:mac

# FÃ¼r Linux
npm run build:linux

# FÃ¼r alle Plattformen
npm run build:all
```

Die fertigen Installer findest du dann im `dist/` Ordner!

## ğŸš€ Schnellstart

### 1. App starten
```powershell
cd desktop
npm install
npm start
```

### 2. API-Key konfigurieren
1. Klicke auf **âš™ï¸ Einstellungen**
2. FÃ¼ge deinen kostenlosen API-Key ein (z.B. von Groq)
3. Klicke auf **Speichern**

### 3. Modell wÃ¤hlen
- WÃ¤hle ein Modell aus dem Dropdown in der Sidebar
- Empfohlen: **âš¡ Groq Llama 3.1 70B**

### 4. Chatten!
- Tippe deine Frage ins Textfeld
- DrÃ¼cke **Enter** zum Senden
- **Shift+Enter** fÃ¼r eine neue Zeile

## ğŸ¯ VerfÃ¼gbare Modelle

Die Desktop-App unterstÃ¼tzt alle 17 kostenlosen Modelle:

### âš¡ Groq (Sehr schnell!)
- Llama 3.1 70B
- Llama 3.3 70B
- Mixtral 8x7B
- Gemma 2 9B

### ğŸ’ Google Gemini
- Gemini 1.5 Flash
- Gemini 1.5 Pro

### ğŸ  Ollama (Lokal)
- Llama 3.1
- Mistral
- CodeLlama
- Gemma 2

### ğŸŒ OpenRouter
- GPT-3.5 Turbo
- Claude 3 Haiku
- Mistral 7B
- Llama 3.1 8B

### ğŸ¤— Hugging Face
- Llama 2
- Mistral 7B
- Zephyr 7B

## ğŸ”‘ API-Keys einrichten

### Groq (Empfohlen)
1. Gehe zu https://console.groq.com
2. Erstelle einen Account
3. Generiere einen API-Key
4. FÃ¼ge ihn in den Einstellungen ein

### Google Gemini
1. Gehe zu https://makersuite.google.com/app/apikey
2. Melde dich an
3. Erstelle einen API-Key
4. FÃ¼ge ihn in den Einstellungen ein

### Ollama (Lokal - kein Key nÃ¶tig!)
1. Installiere Ollama von https://ollama.ai
2. FÃ¼hre aus: `ollama pull llama3.1`
3. Starte Ollama: `ollama serve`
4. Fertig!

## âŒ¨ï¸ Tastenkombinationen

| Taste | Aktion |
|-------|--------|
| **Enter** | Nachricht senden |
| **Shift+Enter** | Neue Zeile |
| **Ctrl+L** | Chat lÃ¶schen |
| **Ctrl+,** | Einstellungen Ã¶ffnen |
| **Ctrl+E** | Chat exportieren |

## ğŸ“ Projektstruktur

```
desktop/
â”œâ”€â”€ main.js              # Electron Main Process
â”œâ”€â”€ preload.js           # Preload Script (IPC Bridge)
â”œâ”€â”€ renderer.js          # Frontend-Logik
â”œâ”€â”€ ai-provider.js       # AI-Provider-Integration
â”œâ”€â”€ index.html           # Haupt-UI
â”œâ”€â”€ styles.css           # Styling
â”œâ”€â”€ package.json         # Dependencies
â””â”€â”€ assets/              # Icons & Bilder
```

## ğŸ› ï¸ Entwicklung

### Dev-Modus starten
```powershell
npm run dev
```

### DevTools Ã¶ffnen
Die App startet automatisch mit DevTools im Dev-Modus (`--dev` Flag)

### Ã„nderungen testen
1. Ã„ndere Code in `renderer.js`, `index.html` oder `styles.css`
2. DrÃ¼cke `Ctrl+R` in der App zum Neu-laden
3. FÃ¼r `main.js` Ã„nderungen: App neu starten

## ğŸ“¦ App-Build Konfiguration

Die App kann fÃ¼r verschiedene Plattformen gebaut werden:

### Windows
- **NSIS Installer** - Klassischer Windows-Installer
- **Portable** - Ohne Installation ausfÃ¼hrbar

### macOS
- **DMG** - Drag & Drop Installation
- **ZIP** - Komprimiertes Archiv

### Linux
- **AppImage** - Universal Linux Format
- **DEB** - FÃ¼r Debian/Ubuntu

## ğŸ’¡ Features im Detail

### Chat-Interface
- Markdown-UnterstÃ¼tzung (fett, kursiv, Code)
- Syntax-Highlighting fÃ¼r Code-BlÃ¶cke
- Auto-Scroll zu neuen Nachrichten
- Zeitstempel fÃ¼r jede Nachricht

### Einstellungen
- Persistente Speicherung mit electron-store
- Separate API-Keys fÃ¼r jeden Provider
- Ollama Host-Konfiguration

### Export
- Exportiere Chats als JSON
- Inkl. Timestamp und Modell-Info
- Importfunktion kann hinzugefÃ¼gt werden

## ğŸ› Fehlerbehebung

**"Electron nicht gefunden"**
```powershell
npm install electron --save-dev
```

**"API-Key Fehler"**
- PrÃ¼fe, ob der Key korrekt in den Einstellungen eingegeben wurde
- Stelle sicher, dass der Key aktiv ist

**"Ollama nicht erreichbar"**
```powershell
ollama serve
```

**"Modell lÃ¤dt nicht"**
```powershell
ollama pull llama3.1
```

## ğŸ¨ Anpassungen

### Design Ã¤ndern
Bearbeite `styles.css` - alle Farben sind in CSS-Variablen definiert:
```css
:root {
    --bg-primary: #1e1e1e;
    --accent: #007acc;
    /* ... weitere Farben */
}
```

### Neue Modelle hinzufÃ¼gen
Bearbeite `ai-provider.js` â†’ `getAvailableModels()`

### Tastenkombinationen Ã¤ndern
Bearbeite `renderer.js` â†’ Event Listeners

## ğŸ“„ Lizenz

MIT License - siehe [LICENSE.md](../LICENSE.md)

## ğŸ¤ Beitragen

Feedback und Pull Requests sind willkommen!

## âš ï¸ Hinweis

Dies ist ein inoffizielles Projekt und steht in keiner Verbindung mit GitHub's offiziellem Copilot.

---

## ğŸ†š CLI vs Desktop

| Feature | CLI | Desktop |
|---------|-----|---------|
| OberflÃ¤che | Terminal | Grafisch |
| Platform | Windows/Mac/Linux | Windows/Mac/Linux |
| Installation | npm global | Installer/Portable |
| Benutzerfreundlichkeit | Entwickler | Alle |
| API-Key Setup | .env Datei | GUI Einstellungen |
| Chat-Export | Manuell | Ein-Klick |

**WÃ¤hle CLI fÃ¼r:** Entwickler, Terminal-Fans, Scripting
**WÃ¤hle Desktop fÃ¼r:** Grafische UI, einfachere Bedienung, bessere UX

---

**Viel SpaÃŸ mit deinem Desktop AI-Assistenten! ğŸš€**
